p8105_hw5_zj2379
================
Zheshu Jiang
2023-11-12

## Problem 1

``` r
library(tidyverse)
```

    ## ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
    ## ✔ dplyr     1.1.3     ✔ readr     2.1.4
    ## ✔ forcats   1.0.0     ✔ stringr   1.5.0
    ## ✔ ggplot2   3.4.3     ✔ tibble    3.2.1
    ## ✔ lubridate 1.9.2     ✔ tidyr     1.3.0
    ## ✔ purrr     1.0.2     
    ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
    ## ✖ dplyr::filter() masks stats::filter()
    ## ✖ dplyr::lag()    masks stats::lag()
    ## ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors

``` r
# Create a city_state variable
homicide_df = read.csv("./homicide-data.csv")|>
 mutate(city_state = paste(city, state, sep = ", "))

#summarize within cities to obtain the total number of homicides and the number of unsolved homicides 
homicide_df1=homicide_df |>
  group_by (city) |>
  summarize(total_homicides=n(),
            unsolved_homicides=sum(disposition %in% c("Closed without arrest","Closed by arrest")))
homicide_df1
```

    ## # A tibble: 50 × 3
    ##    city        total_homicides unsolved_homicides
    ##    <chr>                 <int>              <int>
    ##  1 Albuquerque             378                284
    ##  2 Atlanta                 973                658
    ##  3 Baltimore              2827               1154
    ##  4 Baton Rouge             424                244
    ##  5 Birmingham              800                517
    ##  6 Boston                  614                304
    ##  7 Buffalo                 521                210
    ##  8 Charlotte               687                525
    ##  9 Chicago                5535               1849
    ## 10 Cincinnati              694                434
    ## # ℹ 40 more rows

For the city of Baltimore, MD, use the prop.test function to estimate
the proportion of homicides that are unsolved; save the output of
prop.test as an R object, apply the broom::tidy to this object and pull
the estimated proportion and confidence intervals from the resulting
tidy dataframe.

``` r
baltimore_homicides <- homicide_df %>%
  filter(city == "Baltimore", state == "MD")

# Use prop.test to estimate the proportion of unsolved homicides
unsolved_homicides <- sum(baltimore_homicides$disposition %in% c("Closed without arrest", "Open/No arrest"))
total_homicides <- nrow(baltimore_homicides)

prop_test_result <- prop.test(unsolved_homicides, total_homicides)

# Tidy the result of prop.test using broom::tidy
tidy_prop_test <- broom::tidy(prop_test_result)

# Pull the estimate and confidence intervals
tidy_estimate_ci <- tidy_prop_test %>%
  select(estimate, conf.low, conf.high) %>%
  pull()
```

``` r
# Create a summary dataframe with counts of unsolved and total homicides by city
city_summary <- homicide_df %>%
  group_by(city, state) %>%
  summarise(
    unsolved_homicides = sum(disposition %in% c("Closed without arrest", "Open/No arrest")),
    total_homicides = n(),
    .groups = "drop"
  )

# Use purrr to apply prop.test to each city and tidy the results
tidy_prop_test_results <- city_summary %>%
  mutate(
    prop_test = map2(unsolved_homicides, total_homicides, ~prop.test(.x, .y)),
    tidy_results = map(prop_test, broom::tidy)
  ) %>%
  select(city, state, tidy_results) %>%
  unnest(tidy_results)
```

    ## Warning: There was 1 warning in `mutate()`.
    ## ℹ In argument: `prop_test = map2(unsolved_homicides, total_homicides,
    ##   ~prop.test(.x, .y))`.
    ## Caused by warning in `prop.test()`:
    ## ! Chi-squared approximation may be incorrect

``` r
tidy_proportions_ci <- tidy_prop_test_results %>%
  select(city, state, estimate, conf.low, conf.high)
tidy_proportions_ci
```

    ## # A tibble: 51 × 5
    ##    city        state estimate conf.low conf.high
    ##    <chr>       <chr>    <dbl>    <dbl>     <dbl>
    ##  1 Albuquerque NM       0.386    0.337     0.438
    ##  2 Atlanta     GA       0.383    0.353     0.415
    ##  3 Baltimore   MD       0.646    0.628     0.663
    ##  4 Baton Rouge LA       0.462    0.414     0.511
    ##  5 Birmingham  AL       0.434    0.399     0.469
    ##  6 Boston      MA       0.505    0.465     0.545
    ##  7 Buffalo     NY       0.612    0.569     0.654
    ##  8 Charlotte   NC       0.300    0.266     0.336
    ##  9 Chicago     IL       0.736    0.724     0.747
    ## 10 Cincinnati  OH       0.445    0.408     0.483
    ## # ℹ 41 more rows

``` r
tidy_proportions_ci <- tidy_proportions_ci %>%
  arrange(desc(estimate))
plot <- ggplot(tidy_proportions_ci, aes(x = reorder(city, estimate), y = estimate)) +
  geom_point() +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = 0.2) +
  coord_flip() +  # Flip the axes to make the plot horizontal
  labs(x = "City", y = "Proportion of Unsolved Homicides", title = "Proportion of Unsolved Homicides by City") +
  theme_minimal()

ggsave(filename = "unsolved_homicides_by_city.png", plot = plot, width = 10, height = 8, dpi = 300)
```

## Problem 2

Create a tidy dataframe containing data from all participants, including
the subject ID, arm, and observations over time:

Start with a dataframe containing all file names; the list.files
function will help Iterate over file names and read in data for each
subject using purrr::map and saving the result as a new variable in the
dataframe Tidy the result; manipulate file names to include control arm
and subject ID, make sure weekly observations are “tidy”, and do any
other tidying that’s necessary Make a spaghetti plot showing
observations on each subject over time, and comment on differences
between groups.

``` r
# Get the list of file names
file_names <- list.files(path = "./data", pattern = "*.csv")
file_names
```

    ##  [1] "con_01.csv" "con_02.csv" "con_03.csv" "con_04.csv" "con_05.csv"
    ##  [6] "con_06.csv" "con_07.csv" "con_08.csv" "con_09.csv" "con_10.csv"
    ## [11] "exp_01.csv" "exp_02.csv" "exp_03.csv" "exp_04.csv" "exp_05.csv"
    ## [16] "exp_06.csv" "exp_07.csv" "exp_08.csv" "exp_09.csv" "exp_10.csv"

``` r
# write a function to extract subject id, and arm from the file names
extract_info <- function(filename) {
  subject_id <- str_extract(filename, "\\d+")
  arm <- if_else(str_detect(filename, "^con"), "control", "experimental")
  return(tibble(subject_id = subject_id, arm = arm))
}
info_list <- map(file_names, extract_info)
subject_info <- bind_rows(info_list)
# Print the resulting data frame
print(subject_info)
```

    ## # A tibble: 20 × 2
    ##    subject_id arm         
    ##    <chr>      <chr>       
    ##  1 01         control     
    ##  2 02         control     
    ##  3 03         control     
    ##  4 04         control     
    ##  5 05         control     
    ##  6 06         control     
    ##  7 07         control     
    ##  8 08         control     
    ##  9 09         control     
    ## 10 10         control     
    ## 11 01         experimental
    ## 12 02         experimental
    ## 13 03         experimental
    ## 14 04         experimental
    ## 15 05         experimental
    ## 16 06         experimental
    ## 17 07         experimental
    ## 18 08         experimental
    ## 19 09         experimental
    ## 20 10         experimental

``` r
# write a function to read observations
read_obs <- function(file_path) {
  df <- read_csv(file_path, show_col_types = FALSE)
  observations_list <- as.list(df[1, ])
  observations_list <- lapply(observations_list, as.numeric)
  return(observations_list)
}
 
# use map to read multiple files
file_paths <- list.files(path = "./data", pattern = "*.csv", full.names = TRUE)
all_observations <- map(file_paths, read_obs)
all_observations 
```

    ## [[1]]
    ## [[1]]$week_1
    ## [1] 0.2
    ## 
    ## [[1]]$week_2
    ## [1] -1.31
    ## 
    ## [[1]]$week_3
    ## [1] 0.66
    ## 
    ## [[1]]$week_4
    ## [1] 1.96
    ## 
    ## [[1]]$week_5
    ## [1] 0.23
    ## 
    ## [[1]]$week_6
    ## [1] 1.09
    ## 
    ## [[1]]$week_7
    ## [1] 0.05
    ## 
    ## [[1]]$week_8
    ## [1] 1.94
    ## 
    ## 
    ## [[2]]
    ## [[2]]$week_1
    ## [1] 1.13
    ## 
    ## [[2]]$week_2
    ## [1] -0.88
    ## 
    ## [[2]]$week_3
    ## [1] 1.07
    ## 
    ## [[2]]$week_4
    ## [1] 0.17
    ## 
    ## [[2]]$week_5
    ## [1] -0.83
    ## 
    ## [[2]]$week_6
    ## [1] -0.31
    ## 
    ## [[2]]$week_7
    ## [1] 1.58
    ## 
    ## [[2]]$week_8
    ## [1] 0.44
    ## 
    ## 
    ## [[3]]
    ## [[3]]$week_1
    ## [1] 1.77
    ## 
    ## [[3]]$week_2
    ## [1] 3.11
    ## 
    ## [[3]]$week_3
    ## [1] 2.22
    ## 
    ## [[3]]$week_4
    ## [1] 3.26
    ## 
    ## [[3]]$week_5
    ## [1] 3.31
    ## 
    ## [[3]]$week_6
    ## [1] 0.89
    ## 
    ## [[3]]$week_7
    ## [1] 1.88
    ## 
    ## [[3]]$week_8
    ## [1] 1.01
    ## 
    ## 
    ## [[4]]
    ## [[4]]$week_1
    ## [1] 1.04
    ## 
    ## [[4]]$week_2
    ## [1] 3.66
    ## 
    ## [[4]]$week_3
    ## [1] 1.22
    ## 
    ## [[4]]$week_4
    ## [1] 2.33
    ## 
    ## [[4]]$week_5
    ## [1] 1.47
    ## 
    ## [[4]]$week_6
    ## [1] 2.7
    ## 
    ## [[4]]$week_7
    ## [1] 1.87
    ## 
    ## [[4]]$week_8
    ## [1] 1.66
    ## 
    ## 
    ## [[5]]
    ## [[5]]$week_1
    ## [1] 0.47
    ## 
    ## [[5]]$week_2
    ## [1] -0.58
    ## 
    ## [[5]]$week_3
    ## [1] -0.09
    ## 
    ## [[5]]$week_4
    ## [1] -1.37
    ## 
    ## [[5]]$week_5
    ## [1] -0.32
    ## 
    ## [[5]]$week_6
    ## [1] -2.17
    ## 
    ## [[5]]$week_7
    ## [1] 0.45
    ## 
    ## [[5]]$week_8
    ## [1] 0.48
    ## 
    ## 
    ## [[6]]
    ## [[6]]$week_1
    ## [1] 2.37
    ## 
    ## [[6]]$week_2
    ## [1] 2.5
    ## 
    ## [[6]]$week_3
    ## [1] 1.59
    ## 
    ## [[6]]$week_4
    ## [1] -0.16
    ## 
    ## [[6]]$week_5
    ## [1] 2.08
    ## 
    ## [[6]]$week_6
    ## [1] 3.07
    ## 
    ## [[6]]$week_7
    ## [1] 0.78
    ## 
    ## [[6]]$week_8
    ## [1] 2.35
    ## 
    ## 
    ## [[7]]
    ## [[7]]$week_1
    ## [1] 0.03
    ## 
    ## [[7]]$week_2
    ## [1] 1.21
    ## 
    ## [[7]]$week_3
    ## [1] 1.13
    ## 
    ## [[7]]$week_4
    ## [1] 0.64
    ## 
    ## [[7]]$week_5
    ## [1] 0.49
    ## 
    ## [[7]]$week_6
    ## [1] -0.12
    ## 
    ## [[7]]$week_7
    ## [1] -0.07
    ## 
    ## [[7]]$week_8
    ## [1] 0.46
    ## 
    ## 
    ## [[8]]
    ## [[8]]$week_1
    ## [1] -0.08
    ## 
    ## [[8]]$week_2
    ## [1] 1.42
    ## 
    ## [[8]]$week_3
    ## [1] 0.09
    ## 
    ## [[8]]$week_4
    ## [1] 0.36
    ## 
    ## [[8]]$week_5
    ## [1] 1.18
    ## 
    ## [[8]]$week_6
    ## [1] -1.16
    ## 
    ## [[8]]$week_7
    ## [1] 0.33
    ## 
    ## [[8]]$week_8
    ## [1] -0.44
    ## 
    ## 
    ## [[9]]
    ## [[9]]$week_1
    ## [1] 0.08
    ## 
    ## [[9]]$week_2
    ## [1] 1.24
    ## 
    ## [[9]]$week_3
    ## [1] 1.44
    ## 
    ## [[9]]$week_4
    ## [1] 0.41
    ## 
    ## [[9]]$week_5
    ## [1] 0.95
    ## 
    ## [[9]]$week_6
    ## [1] 2.75
    ## 
    ## [[9]]$week_7
    ## [1] 0.3
    ## 
    ## [[9]]$week_8
    ## [1] 0.03
    ## 
    ## 
    ## [[10]]
    ## [[10]]$week_1
    ## [1] 2.14
    ## 
    ## [[10]]$week_2
    ## [1] 1.15
    ## 
    ## [[10]]$week_3
    ## [1] 2.52
    ## 
    ## [[10]]$week_4
    ## [1] 3.44
    ## 
    ## [[10]]$week_5
    ## [1] 4.26
    ## 
    ## [[10]]$week_6
    ## [1] 0.97
    ## 
    ## [[10]]$week_7
    ## [1] 2.73
    ## 
    ## [[10]]$week_8
    ## [1] -0.53
    ## 
    ## 
    ## [[11]]
    ## [[11]]$week_1
    ## [1] 3.05
    ## 
    ## [[11]]$week_2
    ## [1] 3.67
    ## 
    ## [[11]]$week_3
    ## [1] 4.84
    ## 
    ## [[11]]$week_4
    ## [1] 5.8
    ## 
    ## [[11]]$week_5
    ## [1] 6.33
    ## 
    ## [[11]]$week_6
    ## [1] 5.46
    ## 
    ## [[11]]$week_7
    ## [1] 6.38
    ## 
    ## [[11]]$week_8
    ## [1] 5.91
    ## 
    ## 
    ## [[12]]
    ## [[12]]$week_1
    ## [1] -0.84
    ## 
    ## [[12]]$week_2
    ## [1] 2.63
    ## 
    ## [[12]]$week_3
    ## [1] 1.64
    ## 
    ## [[12]]$week_4
    ## [1] 2.58
    ## 
    ## [[12]]$week_5
    ## [1] 1.24
    ## 
    ## [[12]]$week_6
    ## [1] 2.32
    ## 
    ## [[12]]$week_7
    ## [1] 3.11
    ## 
    ## [[12]]$week_8
    ## [1] 3.78
    ## 
    ## 
    ## [[13]]
    ## [[13]]$week_1
    ## [1] 2.15
    ## 
    ## [[13]]$week_2
    ## [1] 2.08
    ## 
    ## [[13]]$week_3
    ## [1] 1.82
    ## 
    ## [[13]]$week_4
    ## [1] 2.84
    ## 
    ## [[13]]$week_5
    ## [1] 3.36
    ## 
    ## [[13]]$week_6
    ## [1] 3.61
    ## 
    ## [[13]]$week_7
    ## [1] 3.37
    ## 
    ## [[13]]$week_8
    ## [1] 3.74
    ## 
    ## 
    ## [[14]]
    ## [[14]]$week_1
    ## [1] -0.62
    ## 
    ## [[14]]$week_2
    ## [1] 2.54
    ## 
    ## [[14]]$week_3
    ## [1] 3.78
    ## 
    ## [[14]]$week_4
    ## [1] 2.73
    ## 
    ## [[14]]$week_5
    ## [1] 4.49
    ## 
    ## [[14]]$week_6
    ## [1] 5.82
    ## 
    ## [[14]]$week_7
    ## [1] 6
    ## 
    ## [[14]]$week_8
    ## [1] 6.49
    ## 
    ## 
    ## [[15]]
    ## [[15]]$week_1
    ## [1] 0.7
    ## 
    ## [[15]]$week_2
    ## [1] 3.33
    ## 
    ## [[15]]$week_3
    ## [1] 5.34
    ## 
    ## [[15]]$week_4
    ## [1] 5.57
    ## 
    ## [[15]]$week_5
    ## [1] 6.9
    ## 
    ## [[15]]$week_6
    ## [1] 6.66
    ## 
    ## [[15]]$week_7
    ## [1] 6.24
    ## 
    ## [[15]]$week_8
    ## [1] 6.95
    ## 
    ## 
    ## [[16]]
    ## [[16]]$week_1
    ## [1] 3.73
    ## 
    ## [[16]]$week_2
    ## [1] 4.08
    ## 
    ## [[16]]$week_3
    ## [1] 5.4
    ## 
    ## [[16]]$week_4
    ## [1] 6.41
    ## 
    ## [[16]]$week_5
    ## [1] 4.87
    ## 
    ## [[16]]$week_6
    ## [1] 6.09
    ## 
    ## [[16]]$week_7
    ## [1] 7.66
    ## 
    ## [[16]]$week_8
    ## [1] 5.83
    ## 
    ## 
    ## [[17]]
    ## [[17]]$week_1
    ## [1] 1.18
    ## 
    ## [[17]]$week_2
    ## [1] 2.35
    ## 
    ## [[17]]$week_3
    ## [1] 1.23
    ## 
    ## [[17]]$week_4
    ## [1] 1.17
    ## 
    ## [[17]]$week_5
    ## [1] 2.02
    ## 
    ## [[17]]$week_6
    ## [1] 1.61
    ## 
    ## [[17]]$week_7
    ## [1] 3.13
    ## 
    ## [[17]]$week_8
    ## [1] 4.88
    ## 
    ## 
    ## [[18]]
    ## [[18]]$week_1
    ## [1] 1.37
    ## 
    ## [[18]]$week_2
    ## [1] 1.43
    ## 
    ## [[18]]$week_3
    ## [1] 1.84
    ## 
    ## [[18]]$week_4
    ## [1] 3.6
    ## 
    ## [[18]]$week_5
    ## [1] 3.8
    ## 
    ## [[18]]$week_6
    ## [1] 4.72
    ## 
    ## [[18]]$week_7
    ## [1] 4.68
    ## 
    ## [[18]]$week_8
    ## [1] 5.7
    ## 
    ## 
    ## [[19]]
    ## [[19]]$week_1
    ## [1] -0.4
    ## 
    ## [[19]]$week_2
    ## [1] 1.08
    ## 
    ## [[19]]$week_3
    ## [1] 2.66
    ## 
    ## [[19]]$week_4
    ## [1] 2.7
    ## 
    ## [[19]]$week_5
    ## [1] 2.8
    ## 
    ## [[19]]$week_6
    ## [1] 2.64
    ## 
    ## [[19]]$week_7
    ## [1] 3.51
    ## 
    ## [[19]]$week_8
    ## [1] 3.27
    ## 
    ## 
    ## [[20]]
    ## [[20]]$week_1
    ## [1] 1.09
    ## 
    ## [[20]]$week_2
    ## [1] 2.8
    ## 
    ## [[20]]$week_3
    ## [1] 2.8
    ## 
    ## [[20]]$week_4
    ## [1] 4.3
    ## 
    ## [[20]]$week_5
    ## [1] 2.25
    ## 
    ## [[20]]$week_6
    ## [1] 6.57
    ## 
    ## [[20]]$week_7
    ## [1] 6.09
    ## 
    ## [[20]]$week_8
    ## [1] 4.64
